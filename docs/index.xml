<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on ML Hub</title>
    <link>/docs/</link>
    <description>Recent content in Docs on ML Hub</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Apr 2020 15:56:45 +0800</lastBuildDate>
    
	<atom:link href="/docs/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>平台概况</title>
      <link>/docs/intro/</link>
      <pubDate>Wed, 08 Apr 2020 15:34:56 +0800</pubDate>
      
      <guid>/docs/intro/</guid>
      <description> 背景 随着相关技术的研究以及硬件算力的大幅提升，机器学习，尤其是深度学习迎来了巨大的发展，受到了前所未有的关注。需要大量算力的机器学习任务一般依赖于GPU高效的矩阵运算能力，常采用大规模GPU集群并行计算。当前分布式机器学习的架构主要包括PS-Worker架构以及Ring All Reduce架构。然而当前用户在集群中运行机器学习任务仍然存在以下问题：首先为了运行训练任务，用户需要掌握除了学习算法以外较多的内容；其次分布式模型训练执行过程较为繁琐；最后现有调度器暂未考虑使用GPU的训练任务的特殊性。
因此我们设计和开发了分布式机器学习支撑平台ML Hub。核心的设计思想是用户可以为每个机器学习项目创建工作区，在其中借助平台提供的一系列工具开展训练工作流程，从而解决机器学习训练的繁琐过程。
系统架构 ML Hub是一个架构于业界最先进的Kubernetes容器云之上的机器学习平台。基于Kubernetes+Docker+GPU 架构,定位于机器学习的上层应用，免去客户部署环境的麻烦，快速开始深度学习任务。软件基于容器基础，内置多种深度学习框架，提供多种交互式开发及 API 接口，可满足多用户、多场景的需求
技术特色 图形工作界面 表盘式工作界面，从监控页可以看到，ML Hub集群里所有的GPU资源，已分配的GPU资源，所有的计算节点信息、任务信息等。菜单界面平滑直观，所有功能一目了然。
数据存储 基于 ceph 和 nfs 的分布式存储架构，存储容量大、容易横向扩展，由用户创建指定配额的存储用于存放训练数据集、测试数据集、训练结果等。
模型训练 基于 Kubernetes 的容器调度引擎，支持离线训练，成熟稳定；支持 TensorFlow 以及 Pytorch 框架的多机多卡分布式训练，可通过 key-value 对的形式设置超参数；任务训练时，支持可视化及显示 loss 和 accuracy 变化曲线，可实时查看任务训练过程中的 log 输出；可动态调度任务到最优的节点上，保证资源使用的效率；同时支持 Jupyter，Terminal 等多种交互式开发方式和调试。 模型训练、超参数调节、训练结果可视化、日志查看等一系列环节和工具，使用户可以聚焦在核心的算法设计上面，极大提高了工作效率。通过资源配额、任务调度和容错，使模型训练任务高效可靠；分布式任务使大规模网络模型的训练性能大大提高。 </description>
    </item>
    
    <item>
      <title>在线开发环境</title>
      <link>/docs/webdev/</link>
      <pubDate>Wed, 08 Apr 2020 15:56:30 +0800</pubDate>
      
      <guid>/docs/webdev/</guid>
      <description> 功能介绍 在线开发环境是ML Hub为用户提供的关键组件之一。它提供了在线查看、编写代码 代码版本管理、集成式命令行终端等的功能，使用体验与微软的vscode一致。
在线开发环境还集成了任务管理工具，可以通过命令行发布训练任务或完成模型部署。发布训练任务后还可以实时查看训练日志。
如何使用 </description>
    </item>
    
    <item>
      <title>分布式资源调度</title>
      <link>/docs/schedule/</link>
      <pubDate>Wed, 08 Apr 2020 15:56:17 +0800</pubDate>
      
      <guid>/docs/schedule/</guid>
      <description></description>
    </item>
    
    <item>
      <title>自动化超参数训练</title>
      <link>/docs/hyperparameter/</link>
      <pubDate>Wed, 08 Apr 2020 15:56:45 +0800</pubDate>
      
      <guid>/docs/hyperparameter/</guid>
      <description>功能介绍 自动化的调参是MLhub调参模块的关键功能，主要的应用场景是超参调优。调参模块提供了多种流行的自动调参算法，包括常用的网格搜索（Grid search）、随机搜索（Random search）以及更高级的继续随机序列建模的TPE算法等。
使用调参模块只需要简单的几个步骤，首先，用户在前端定义自己的搜索空间，搜索空间会被整理成指定的JSON格式，并发送到后端。然后，用户在自己的代码中进行修改，只需要在调用我们提供的api来获得新的参数以及报告数据（数据包括性能指标的变化和Loss的变化等）。最后启动任务。后端会根据用户的配置在集群中创建一个Pod来完成这次实验。实验的中间结果和最终结果会被展示在前端。用户可以根据可视化的结果，选择较优的参数或者调整自己的代码。
模块设计         图 1: 模块设计    图1通过一个完整的调参任务流程展示了自动化超参数训练的模块设计，图中的标号代表了数据的传递过程：
 前端将用户定义的实验配置信息，包括搜索空间、启动指令等发送给后端的Launcher
 Launcher根据实验配置信息，在集群中创建Experiment Pod来完成这次实验，并将实验的配置信息挂载到Experiment Pod中
 Experiment Pod由Manager和Tuner两个容器构成，Manager负责控制实验的进度，对实验进行统一管理，而Tuner中封装了若干调参算法。Manager在创建新的Trial时，会向Tuner请求新的一组超参数，以及报告已经完成的Trial的结果。
 Tuner会根据已经完成的Trial的结果，预测搜索空间中更好的参数，并发送给Manager
 Experiment Pod通过K8s api向部署在集群中的TF/Pytorch operator发送请求，要求新建tfjob/pytorchjob。
 TF/Pytorch operator根据Experiment Pod的请求创建出Trial Pod。Trial Pod会挂载用户的代码和数据卷，并进行训练和测试。
 Trial Pod向Experiment Pod中的Manager报告本次Trial的结果（包括Loss的变化，最终的准确度等）
 Manager获得结果后，将其连同Trial的信息存入数据库。并判断是否要继续进行实验。
 前端可以向后端请求实验的数据，并将其可视化，展示给用户，方便用户选择较优的参数。
  如何使用 修改训练代码 我们提供了一个pytorch的超参数训练的例子,首先，我们需要修改训练代码，通过调用dlkit_utils.py中给出的api获取一组参数以及报告训练结果:
# dlkit_util.py # 获取一组超参数，类型为dict def get_parameter(): # 报告最终的训练效果，通常是准确度等评估数据 def report_final_result(data): # 报告每个epoch的loss数据，用于可视化展示 def report_loss(data): # 报告每个epoch的训练效果，用于可视化展示 def report_intermediate_result(data):  我们需要修改训练代码：</description>
    </item>
    
    <item>
      <title>模型版本控制</title>
      <link>/docs/versioncontrol/</link>
      <pubDate>Wed, 08 Apr 2020 15:56:10 +0800</pubDate>
      
      <guid>/docs/versioncontrol/</guid>
      <description>背景 版本控制在传统软件开发的管理过程中发挥着重要作用。大量开发者通过Git，SVN等版本控制工具，或是GitHub等平台进行开发过程的生命周期管理。而在机器学习和深度学习开发的过程中，通常需要开发人员自行进行版本控制，大大增加了开发人员的负担和项目管理的难度。
版本控制的目标 内容追踪 版本控制需要追踪软件开发过程中文件的内容变化，并能够对不同版本的文件内容差异进行表示。
版本切换 版本控制需要记录用户提交的所有版本，并能够在不同版本之间进行切换。
协同开发 版本控制需要支撑开发团队进行协同开发，包括版本的分支，合并等功能。
传统版本控制的局限 由于模型开发过程与传统软件开发过程有所不同，传统的版本控制工具在模型开发过程中难以发挥出理想的效果。
    传统软件开发 模型开发     核心产品 代码 模型   核心文件 文本文件 二进制文件   文件规模 Byte/KB MB/GB   迭代方式 文本编辑 迭代训练    传统版本控制的核心思想是追踪文件内容的变化，在此基础上构建版本切换和协同开发机制。由于上述不同，传统版本控制工具和平台在对模型进行管理时难以实现内容变化的有效追踪，高效的版本切换和协同开发机制。
内容追踪 传统版本控制对文件的文本内容变化进行追踪。如Git中可以通过git diff命令计算两个版本之间的文件内容差异。
由于模型文件并非通过文本编辑而是通过重新训练生成，且模型文件通常为二进制文件，传统的版本控制工具难以对模型文件的内容变化进行刻画和有意义的表示。
版本切换 传统版本控制工具通过对文件内容和版本差异的记录计算出目标版本的文件内容，并写入对应文件。如Git中可以通过git checkout命令切换到指定版本。
由于模型文件版本差异较大，通过传统版本控制工具进行版本记录的额外存储开销过大且通过版本切换命令计算目标版本的过程计算量较大，在版本切换的效率和存储开销方面远不如开发人员手动维护的版本记录。
协同开发 传统版本控制工具通过分支，合并，拉取更新等方式进行协同开发。例如Git中可以通过git branch，git merge，git pull等命令进行协同开发。
由于模型文件规模较大且通常为二进制文件，不同版本的合并难以进行，且远程仓库版本的拉取速度较慢。
MLHUB版本控制的特色 MLHUB从模型开发过程的特征出发，以模型为核心实现简单易用的版本控制机制。
内容追踪 MLHUB追踪模型的版本变化，对不同版本的模型进行清晰刻画并进行有意义的版本差异表示。
版本切换 MLHUB从模型的特征出发，实现适合模型文件的版本存储和切换机制，实现节约存储空间和高效切换版本的目标。
协同开发 MLHUB基于模型的结构实现模型的解构和复用，构建适用于模型文件的分支与合并机制并降低与远程仓库的通信压力。</description>
    </item>
    
    <item>
      <title>无服务化模型发布</title>
      <link>/docs/servless/</link>
      <pubDate>Wed, 08 Apr 2020 15:56:22 +0800</pubDate>
      
      <guid>/docs/servless/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>